{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "nt = 100\n",
    "k = 50\n",
    "x = torch.distributions.uniform.Uniform(low=-1 * torch.ones(n), high=torch.ones(n)).sample()\n",
    "x, _ = torch.sort(x)\n",
    "x = x.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dist = torch.distributions.normal.Normal(loc=0, scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "p = torch.sigmoid(z_dist.sample() + z_dist.sample() * x + z_dist.sample() * x**2 -4)\n",
    "phi = torch.sigmoid(z_dist.sample() + z_dist.sample() * x + z_dist.sample() * x**2 + 1)\n",
    "gamma = torch.sigmoid(z_dist.sample() + z_dist.sample() * x + z_dist.sample() * x**2 -2)\n",
    "psi0 = torch.sigmoid(z_dist.sample() + z_dist.sample() * x + z_dist.sample() * x**2 -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x.numpy(), phi.numpy())\n",
    "plt.scatter(x.numpy(), gamma.numpy())\n",
    "plt.scatter(x.numpy(), psi0.numpy())\n",
    "plt.scatter(x.numpy(), p.numpy())\n",
    "plt.xlabel('Covariate value')\n",
    "plt.ylabel('')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(['phi', 'gamma', 'psi0', 'p'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 = torch.distributions.Bernoulli(probs = psi0).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.zeros((n, nt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[:, 0] = z0.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(1, nt):\n",
    "    psi = z[:, t - 1] * phi.squeeze() + (1. - z[:, t - 1]) * gamma.squeeze()\n",
    "    z[:, t] = torch.distributions.Bernoulli(probs = psi).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7, 10))\n",
    "plt.imshow(z.numpy(), aspect=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.distributions.Binomial(total_count=k, probs=z * p).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7, 10))\n",
    "plt.imshow(y.numpy(), aspect=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # affine operations: y = Wx + b\n",
    "        self.fc1 = nn.Linear(1, 64)\n",
    "        self.fc2 = nn.Linear(64, 4)\n",
    "        self.nt = nt\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        output = self.fc2(x)\n",
    "        phi = torch.sigmoid(output[:, [0]].repeat(1, self.nt - 1))\n",
    "        gamma = torch.sigmoid(output[:, [1]].repeat(1, self.nt - 1))\n",
    "        psi0 = torch.sigmoid(output[:, [2]])\n",
    "        logit_p = output[:, [3]].repeat(1, self.nt)\n",
    "\n",
    "        return phi, gamma, psi0, logit_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device)\n",
    "running_loss = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(x, y)\n",
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=32,\n",
    "                        shuffle=True, \n",
    "                        num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 100\n",
    "optimizer = torch.optim.Adam(net.parameters(), weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loglik2(y_j, psi0_j, gamma_j, phi_j, logit_p_j):\n",
    "    \"\"\" Calculate log likelihood with scaled forward algorithm\n",
    "    \n",
    "    Some nice detail here: https://pdfs.semanticscholar.org/4ce1/9ab0e07da9aa10be1c336400c8e4d8fc36c5.pdf\n",
    "    \"Some mathematics for HMM\" by Dawei Shen, October 13th, 2008\n",
    "    \"\"\"\n",
    "    batch_size = y_j.shape[0]\n",
    "    nt = y_j.shape[1]\n",
    "    \n",
    "    pr_y_present = torch.exp(torch.distributions.binomial.Binomial(total_count=k, logits=logit_p_j).log_prob(y_j))\n",
    "    po = torch.stack((pr_y_present, (y_j==0).to(device, dtype=torch.float64)), -1) # nt, 2b\n",
    "    phi_0_j = torch.cat((psi0_j, 1-psi0_j), -1)\n",
    "    \n",
    "    Omega = torch.stack((torch.stack((phi_j, 1 - phi_j), -1), \n",
    "                       torch.stack((gamma_j, 1 - gamma_j), -1)), \n",
    "                      -2) # dims: (batch_size, nt-1, 2, 2)\n",
    "    assert Omega.shape == (batch_size, nt - 1, 2, 2)\n",
    "    \n",
    "    c = list()\n",
    "    alpha_raw = torch.bmm(phi_0_j.unsqueeze(1), \n",
    "                          torch.diag_embed(po[:, 0, :], dim1=-2, dim2=-1)\n",
    "                         )\n",
    "    c.append((torch.ones(batch_size, 1).to(device) / torch.sum(alpha_raw, dim=-1)).squeeze())\n",
    "    alpha = c[-1].view(-1, 1, 1) * alpha_raw\n",
    "    \n",
    "    for t in range(nt - 1):\n",
    "        alpha_raw = torch.bmm(alpha, \n",
    "                          torch.bmm(\n",
    "                              Omega[:, t, :, :], \n",
    "                              # batch diagonal\n",
    "                              torch.diag_embed(po[:, t+1, :], dim1=-2, dim2=-1),\n",
    "                            )\n",
    "                         )\n",
    "        c.append((torch.ones(batch_size, 1).to(device) / torch.sum(alpha_raw, dim=-1)).squeeze())\n",
    "        alpha = c[-1].view(-1, 1, 1) * alpha_raw\n",
    "    c_stacked = torch.stack(c, -1)\n",
    "    return -torch.sum(torch.log(c_stacked), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(n_epoch)):\n",
    "    for i_batch, xy in enumerate(dataloader):\n",
    "        x_i, y_i = xy\n",
    "        x_i = x_i.to(device)\n",
    "        y_i = y_i.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        phi_i, gamma_i, psi0_i, logit_p_i, = net(x_i)\n",
    "\n",
    "        # compute the negative log likliehood\n",
    "        ll = get_loglik2(y_i, psi0_i, gamma_i, phi_i, logit_p_i)\n",
    "        assert torch.sum(torch.isnan(ll)) < 1\n",
    "        loss = -torch.mean(ll)        \n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "        running_loss.append(loss.cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(len(running_loss))], \n",
    "            np.array(running_loss), \n",
    "            alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_hat, gamma_hat, psi0_hat, p_hat = net(x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x.numpy(), phi.numpy())\n",
    "plt.scatter(x.numpy(), phi_hat[:, 0].cpu().detach().numpy(), color='r')\n",
    "plt.title('Persistence probabilities')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x.numpy(), gamma.numpy())\n",
    "plt.scatter(x.numpy(), gamma_hat[:, 0].cpu().detach().numpy(), color='r')\n",
    "plt.title('Colonization probabilities')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x.numpy(), psi0.numpy())\n",
    "plt.scatter(x.numpy(), psi0_hat.cpu().detach().numpy(), color='r')\n",
    "plt.title('Initial occupancy probabilities')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x.numpy(), p.numpy())\n",
    "plt.scatter(x.numpy(), torch.sigmoid(p_hat[:, 0]).cpu().detach().numpy(), color='r')\n",
    "plt.title('Detection probabilities')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
