{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A neural hidden Markov model: capture-recapture example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a function that relates a covariate to survival and detection probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "nx = 100\n",
    "x = np.linspace(-2, 2, nx, dtype=np.float32).reshape(-1,1)\n",
    "\n",
    "def kernel(x, theta):\n",
    "    m, n = np.meshgrid(x, x)\n",
    "    sqdist = abs(m-n)**2\n",
    "    return np.exp(- theta * sqdist)\n",
    "\n",
    "def sigmoid(x, derivative=False):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "K = kernel(x, theta=.5)\n",
    "jitter = 1e-5* np.eye(nx)\n",
    "L = np.linalg.cholesky(K + jitter)\n",
    "zvals = np.random.normal(size=(nx, 3))\n",
    "\n",
    "f_survival = sigmoid(np.dot(L, zvals[:, 0]) + x[:, 0] + 4)\n",
    "f_detection = sigmoid(np.dot(L, zvals[:, 1]) - x[:, 0]**2)\n",
    "f_recovery = sigmoid(np.dot(L, zvals[:, 2]) - .5*x[:, 0]**2)\n",
    "\n",
    "plt.plot(x, f_survival)\n",
    "plt.plot(x, f_detection)\n",
    "plt.plot(x, f_recovery)\n",
    "plt.legend(['Survival', 'Detection', 'Recovery'])\n",
    "plt.xlabel('Covariate')\n",
    "plt.ylabel('Probability')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_survival.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model formulation\n",
    "\n",
    "Our model formulation is similar to the first simple case described in https://projecteuclid.org/euclid.aoas/1380804813\n",
    "\n",
    "We assume that all individuals are initially captured, marked, and released on timestep $t=0$. The state of an individual on time step $t$ is denoted $z_{t}$. Individuals are either alive ($z_{t} = 0$), recently dead such that their bodies are discoverable and marks identifiable ($z_{t} = 1$), or long dead such that their bodies are not discoverable and/or marks are no longer identifiable ($z_t = 2$). The survival probability is denoted $\\phi_t$, where $\\phi_t = P(z_{t + 1} = 0 \\mid z_{t} = 0)$. \n",
    "\n",
    "Observations $y_{t}$ are made on time steps $t=1, ..., T$, and if an individual is detected alive on timestep $t$, $y_{t} = 1$, and if an individual is detected as recently dead $y_t=2$, otherwise if the individual is not detected $y_{t} = 0$. \n",
    "\n",
    "At time $t$, the transition probability matrix $\\pmb{\\Gamma}_t$ contains the probability of transitioning from row $i$ to column $j$:\n",
    "\n",
    "$$\\pmb{\\Gamma}_t = \n",
    "\\begin{bmatrix}\n",
    "    \\phi_t  & 1 - \\phi_t & 0 \\\\\n",
    "    0       & 0          & 1 \\\\\n",
    "    0       & 0          & 1\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Let $\\pmb{\\Omega}_t$ denote an emission matrix containing state-dependent observation probabilities:\n",
    "\n",
    "$$\n",
    "\\pmb{\\Omega}_t =\n",
    "\\begin{bmatrix}\n",
    "    1-p_t         & p_t & 0         \\\\\n",
    "    1 - \\lambda_t & 0   & \\lambda_t \\\\\n",
    "    1             &  0  & 0\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "where $p_t$ is the probability of detecting an individual on timestep $t$, conditional on the individual being alive, and $\\lambda_t$ is the probability of recovering a recently dead individual on timestep $t$ that has died since timestep $t-1$. \n",
    "The rows of the emission matrix correspond to states (alive, recently dead, long dead), and the columns correspond to observations (not detected, detected alive, detected dead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# States are alive (0), recently dead (1), long dead (2)\n",
    "n_state = 3\n",
    "\n",
    "# Set up simulation parameters:\n",
    "initial_population_size = 1000\n",
    "n_timesteps = 50\n",
    "n_tp1 = n_timesteps + 1\n",
    "indices = np.random.randint(nx, size=n_tp1)\n",
    "x_vals = x[indices, 0]\n",
    "pr_survival = f_survival[indices]\n",
    "pr_detection = f_detection[indices]\n",
    "pr_recovery = f_recovery[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate transition matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Psi = np.zeros((n_state, n_state, n_timesteps))\n",
    "for t in range(n_timesteps):\n",
    "    Psi[0, 0, t] = pr_survival[t]       # survive\n",
    "    Psi[0, 1, t] = 1 - pr_survival[t]   # die\n",
    "    Psi[1, 2, t] = 1                    # recent dead become long dead\n",
    "    Psi[2, 2, t] = 1                    # long dead remain long dead\n",
    "    assert all(np.sum(Psi[:, :, t], 1) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate latent states ($z$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate latent states\n",
    "z = np.zeros((initial_population_size, n_tp1), dtype=np.long)\n",
    "for t in range(1, n_tp1):\n",
    "    for i in range(initial_population_size):\n",
    "        was_alive = z[i, t - 1] == 0\n",
    "        if was_alive:\n",
    "            survived = np.random.binomial(1, pr_survival[t - 1])\n",
    "            if not survived:\n",
    "                # become recently dead\n",
    "                z[i, t] = 1\n",
    "        else:\n",
    "            # become or remain long dead\n",
    "            z[i, t] = 2\n",
    "\n",
    "# in the first (dummy) timestep, all individuals are alive: z_i = 0 for all i\n",
    "assert all(z[:, 0] == 0)\n",
    "\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the states over time for each individual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/47269390/numpy-how-to-find-first-non-zero-value-in-every-column-of-a-numpy-array?noredirect=1&lq=1\n",
    "def first_nonzero(arr, axis, invalid_val=n_timesteps):\n",
    "    mask = arr!=0\n",
    "    return np.where(mask.any(axis=axis), mask.argmax(axis=axis), invalid_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7, 10))\n",
    "plt.imshow(z[np.argsort(first_nonzero(z, axis=1)), :], aspect=.1)\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ylabel('Individuals')\n",
    "plt.title('True states')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate observations\n",
    "\n",
    "At timesteps $t=1,..., T$ (but not $t=0$), surveys are conducted. Alive individuals are detected with probability $p_t$, and the recent dead are recovered with probability $\\lambda_t$. We assume dead individuals are not detected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Omega = np.zeros((n_state, 3, n_tp1)) # (states, observations, timesteps)\n",
    "for t in range(n_tp1):\n",
    "    Omega[0, 0, t] = 1 - pr_detection[t]  # alive not detected\n",
    "    Omega[0, 1, t] = pr_detection[t]      # alive and detected\n",
    "    Omega[1, 0, t] = 1 - pr_recovery[t]   # recent dead, not recovered\n",
    "    Omega[1, 2, t] = pr_recovery[t]       # recent dead, recovered\n",
    "    Omega[2, 0, t] = 1                    # long-dead, never detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((initial_population_size, n_tp1))\n",
    "for t in range(n_tp1):\n",
    "    for i in range(initial_population_size):\n",
    "        if (z[i, t] == 0):\n",
    "            y[i, t] = np.random.binomial(1, pr_detection[t]) # y=1 --> detected\n",
    "        if (z[i, t] == 1):\n",
    "            recovered = np.random.binomial(1, pr_recovery[t])\n",
    "            if recovered:\n",
    "                y[i, t] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7, 10))\n",
    "plt.imshow(y[np.argsort(first_nonzero(z, axis=1)), :], aspect=.1)\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ylabel('Individuals')\n",
    "plt.title('Detection data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a neural network to map inputs to parameters\n",
    "\n",
    "For this case study, one network template is used to construct three networks: one for survival, one for detection, and one for recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        output = torch.sigmoid(self.fc3(x))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_survival = Net()\n",
    "net_detection = Net()\n",
    "net_recovery = Net()\n",
    "running_loss = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a data loader for the simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.from_numpy(x_vals.astype(np.float32)).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tensor = torch.from_numpy(y.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(y_tensor)\n",
    "    \n",
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=64,\n",
    "                        shuffle=True, \n",
    "                        num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions to compute the log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loglik(y, Gamma, Omega):\n",
    "    \"\"\" Get log likelihood of a capture history w/ forward algorithm. \"\"\"\n",
    "    delta = torch.tensor([[1., 0., 0.]])\n",
    "    prods = []\n",
    "    running_prods = [torch.eye(n_state)]\n",
    "\n",
    "    for t in range(1, n_tp1):\n",
    "        running_prods.append(torch.mm(running_prods[t - 1], \n",
    "                                      torch.mm(Gamma[t - 1], \n",
    "                                               torch.diag(Omega[t, :, y[t]]))))\n",
    "    return torch.sum(torch.mm(delta, running_prods[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models\n",
    "\n",
    "The neural networks are trained simultaneously by passing the parameters for each to the same optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 100\n",
    "optimizer = torch.optim.Adam(list(net_survival.parameters()) + \n",
    "                             list(net_detection.parameters()) + \n",
    "                             list(net_recovery.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(n_epoch)):\n",
    "    for i_batch, y_batch in enumerate(dataloader):\n",
    "        capture_histories = y_batch[0]\n",
    "        optimizer.zero_grad()\n",
    "        phi = net_survival(x_tensor)\n",
    "        p_hat = net_detection(x_tensor)\n",
    "        lamb = net_recovery(x_tensor)\n",
    "        Gamma = torch.stack((torch.cat((phi, 1-phi, torch.zeros_like(phi)), 1), \n",
    "                             torch.tensor([0., 0., 1.]).expand(n_tp1, -1),\n",
    "                             torch.tensor([0., 0., 1.]).expand(n_tp1, -1)), \n",
    "                            1)\n",
    "        Omega = torch.stack((torch.cat((1 - p_hat, p_hat, torch.zeros_like(p_hat)), 1), \n",
    "                             torch.cat((1 - lamb, torch.zeros_like(lamb), lamb), 1),\n",
    "                             torch.tensor([1., 0., 0.]).expand(n_tp1, -1)), \n",
    "                    1)        \n",
    "        nlls = []\n",
    "        for j in range(capture_histories.shape[0]):\n",
    "            nlls.append(torch.log(get_loglik(capture_histories[j, :], Gamma, Omega)))\n",
    "        nll = -torch.mean(torch.stack(nlls))\n",
    "        nll.backward()\n",
    "        optimizer.step()\n",
    "        running_loss.append(nll.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([i for i in range(len(running_loss))], \n",
    "             np.array(running_loss), \n",
    "            alpha=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect estimated relationships between covariates and process parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_vals, pr_survival)\n",
    "plt.scatter(x_vals, phi[:, 0].detach().numpy())\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(['True', 'Estimated'], loc = 'lower right')\n",
    "plt.xlabel('Covariate')\n",
    "plt.ylabel('Survival probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_vals, pr_detection)\n",
    "plt.scatter(x_vals, p_hat[:, 0].detach().numpy())\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(['True', 'Estimated'])\n",
    "plt.xlabel('Covariate')\n",
    "plt.ylabel('Detection probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_vals, pr_recovery)\n",
    "plt.scatter(x_vals, lamb[:, 0].detach().numpy())\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(['True', 'Estimated'])\n",
    "plt.xlabel('Covariate')\n",
    "plt.ylabel('Recovery probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
